{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper \"Distance and Similarity Measures Effect on the Performance of K-Nearest Neighbor Classifier\" showed how effective the Hassanet metric function can be when compared to a broad range of other metrics for a 1-NN algorithm.\n",
    "Original paper: https://arxiv.org/pdf/1708.04321.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation\n",
    "The formula in the paper for the hassanet metric contradicts previous definitions by the author (https://arxiv.org/pdf/1501.00687.pdf) because of a missing 1 in the denominator; we will consider the version with the 1 since it is the one used in the previous papers and that holds the properties desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My hypthesis is that the significance in results is due to the fact the data was not standardized. This would mean we do not expect similar results if the data was standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T00:10:50.993074Z",
     "start_time": "2019-02-11T00:10:50.972719Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer, load_diabetes, load_wine\n",
    "\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T23:46:50.179541Z",
     "start_time": "2019-02-10T23:46:50.117152Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets = {\"cancer\": load_breast_cancer(), \"diabetes\": load_diabetes(), \"wine\": load_wine()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the different metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T23:18:47.356825Z",
     "start_time": "2019-02-10T23:18:47.343865Z"
    }
   },
   "outputs": [],
   "source": [
    "v1 = [5.1, 3.5, 1.4, 0.3]\n",
    "v2 = [5.4, 3.4, 1.7, 0.2]\n",
    "def test_func(func, num, tol=0.0001):\n",
    "    if not (num-tol < func(v1, v2) < num+tol):\n",
    "        raise ValueError(\"Error on function!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T23:18:50.342212Z",
     "start_time": "2019-02-10T23:18:50.310290Z"
    }
   },
   "outputs": [],
   "source": [
    "def HasD(x, y):\n",
    "    total = 0\n",
    "    for xi, yi in zip(x, y):\n",
    "        min_value = min(xi, yi)\n",
    "        max_value = max(xi, yi)\n",
    "        total += 1 # we sum the 1 in both cases\n",
    "        if min_value >= 0:\n",
    "            total -= (1 + min_value) / (1 + max_value)\n",
    "        else:\n",
    "            # min_value + abs(min_value) = 0, so we ignore that\n",
    "            total -= 1 / (1 + max_value + abs(min_value))\n",
    "    return total\n",
    "\n",
    "test_func(HasD, 0.2572)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T23:18:53.368499Z",
     "start_time": "2019-02-10T23:18:53.359736Z"
    }
   },
   "outputs": [],
   "source": [
    "def LD(x, y):\n",
    "    total = 0\n",
    "    for xi, yi in zip(x, y):\n",
    "        total += math.log(1 + abs(xi-yi))\n",
    "    return total\n",
    "\n",
    "test_func(LD, 0.7153)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T23:21:25.722113Z",
     "start_time": "2019-02-10T23:21:25.710530Z"
    }
   },
   "outputs": [],
   "source": [
    "funcs = {\n",
    "    \"HasD\": HasD,\n",
    "    \"LD\": LD,\n",
    "    \"CanD\": \"canberra\",\n",
    "    \"L2\": \"euclidean\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T00:04:57.004392Z",
     "start_time": "2019-02-11T00:04:56.983764Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_experiment(metric_func, data, testing=False):\n",
    "    \"\"\"\n",
    "    testing: if passed, uses just 0.1% of data.\n",
    "    \"\"\"\n",
    "    if testing:\n",
    "        x, _, y, _ = train_test_split(data.data, data.target, test_size=0.90)\n",
    "    else:\n",
    "        x, y = data.data, data.target\n",
    "        \n",
    "    # Create standardized train/test\n",
    "    train_data, test_data, train_y, test_y = train_test_split(x, y, test_size=0.34)\n",
    "    scaler = StandardScaler()\n",
    "    train_data = scaler.fit_transform(train_data)\n",
    "    test_data = scaler.transform(test_data)\n",
    "    \n",
    "    clf = KNeighborsClassifier(n_neighbors=1, metric=metric_func, n_jobs=3)\n",
    "    clf.fit(train_data, train_y)\n",
    "    preds = clf.predict(test_data)\n",
    "    return accuracy_score(test_y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T00:11:35.020937Z",
     "start_time": "2019-02-11T00:11:26.046274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.75 s, sys: 192 ms, total: 1.94 s\n",
      "Wall time: 8.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "results = pd.DataFrame(index=funcs.keys(), columns=datasets.keys())\n",
    "for metric_name, metric_func in funcs.items():\n",
    "    for data_name, data in datasets.items():\n",
    "        # Not sure why cancer isnt working\n",
    "        if data_name == \"cancer\":\n",
    "            continue\n",
    "        avg_score = 0\n",
    "        for _ in range(10):\n",
    "            avg_score += run_experiment(metric_func, data, testing=True)\n",
    "        avg_score /= 10\n",
    "        results.loc[metric_name, data_name] = avg_score\n",
    "        \n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T00:11:37.812312Z",
     "start_time": "2019-02-11T00:11:37.808672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.956639766693115\n"
     ]
    }
   ],
   "source": [
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T00:11:41.907108Z",
     "start_time": "2019-02-11T00:11:41.884734Z"
    }
   },
   "outputs": [],
   "source": [
    "results.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
